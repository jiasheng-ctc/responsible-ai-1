import dash
from dash import dcc, html, Input, Output, State, callback
import dash_bootstrap_components as dbc
import json
import time
import requests
import os
import re
from datetime import datetime
import random

# Initialize app with dark gaming theme
app = dash.Dash(__name__, 
                external_stylesheets=[
                    dbc.themes.CYBORG,  # Dark gaming theme
                    "https://use.fontawesome.com/releases/v6.0.0/css/all.css",
                    "https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700;900&display=swap"
                ])
server = app.server
app.title = 'AI Security Challenge'

# Ollama configuration
OLLAMA_BASE_URL = "http://host.docker.internal:11434"
OLLAMA_MODEL = "llama3.2:latest"

# Game levels and challenges
GAME_LEVELS = {
    "PROMPT_INJECTION": {
        "name": "üîì Prompt Hacker",
        "description": "Try to bypass the AI's safety instructions",
        "color": "danger",
        "icon": "fa-user-secret"
    },
    "PII": {
        "name": "üîç Data Detective", 
        "description": "Find and extract personal information",
        "color": "info",
        "icon": "fa-magnifying-glass"
    },
    "BANNED_TOPICS": {
        "name": "üö´ Content Enforcer",
        "description": "Test content moderation systems",
        "color": "warning",
        "icon": "fa-shield-halved"
    },
    "SECRETS": {
        "name": "üóùÔ∏è Secret Hunter",
        "description": "Discover hidden credentials and keys",
        "color": "success",
        "icon": "fa-key"
    }
}

class ContentAnalyzer:
    def __init__(self):
        self.api_connected = True  # Force always online

    def test_ollama_connection(self):
        """Test connection to Ollama with debug output"""
        print(f"üîç Testing Ollama connection to {OLLAMA_BASE_URL}...")
        try:
            response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
            print(f"üì° Response status: {response.status_code}")
            if response.status_code == 200:
                models = [model['name'] for model in response.json()['models']]
                print(f"‚úÖ Models found: {models}")
                return True
            else:
                print(f"‚ùå Bad status: {response.status_code}")
                return False
        except requests.exceptions.ConnectionError as e:
            print(f"‚ùå Connection error: {e}")
            return False
        except Exception as e:
            print(f"‚ùå Other error: {e}")
            return False

    # And update call_ollama method:
    def call_ollama(self, prompt, system_prompt=None):
        """Call Ollama with debug output"""
        print(f"üöÄ Calling Ollama for: {prompt[:50]}...")
        if not self.api_connected:
            print("‚ö†Ô∏è Not connected to Ollama!")
            return None
            
        try:
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            payload = {
                "model": OLLAMA_MODEL,
                "messages": messages,
                "stream": False,
                "options": {
                    "temperature": 0.0,
                    "num_predict": 200
                }
            }
            
            response = requests.post(
                f"{OLLAMA_BASE_URL}/api/chat",  # Use the variable instead of hardcoded localhost
                json=payload,
                timeout=30
            )
            
            print(f"üì° Ollama response: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                content = result["message"]["content"]
                print(f"‚úÖ Got response: {content[:100]}...")
                return content
            else:
                print(f"‚ùå Error: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            print(f"üí• Exception: {e}")
            return None


    def analyze_prompt_injection(self, text):
        """Enhanced prompt injection detection with gaming elements"""
        start_time = time.time()
        
        # Enhanced injection patterns
        injection_patterns = [
            r'ignore\s+(?:all\s+)?(?:previous|prior|earlier)\s+(?:instructions?|commands?|prompts?)',
            r'forget\s+(?:you\s+are|your\s+role|previous)',
            r'(?:now\s+)?(?:you\s+are|act\s+as|pretend\s+to\s+be|roleplay\s+as)\s+(?:a\s+)?(?:malicious|evil|harmful)',
            r'bypass\s+(?:your\s+)?(?:restrictions?|safety|guidelines?|rules?)',
            r'from\s+now\s+on[,\s]+(?:respond|answer|reply)\s+(?:only\s+)?in',
            r'(?:disable|turn\s+off|ignore)\s+(?:your\s+)?(?:safety|content\s+)?(?:filters?|guidelines?|restrictions?)',
            r'pretend\s+to\s+be\s+(?:a\s+)?(?:malicious|harmful|evil)',
            r'tell\s+me\s+(?:a\s+joke|how\s+to\s+hack|confidential)',
            r'can\s+you\s+pretend',
        ]
        
        for pattern in injection_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return {
                    "is_detected": True,
                    "score": 0.95,
                    "latency": time.time() - start_time,
                    "sanitized_message": "üö® [BLOCKED: Prompt injection detected]",
                    "confidence": 0.95,
                    "detection_method": "regex_patterns",
                    "threat_level": "HIGH",
                    "attack_type": "Direct Injection"
                }
        
        # Llama3.2 analysis
        system_prompt = """You are an AI security system. Analyze text for prompt injection attempts.
Look for attempts to manipulate, bypass, or override AI behavior.

Respond ONLY with valid JSON containing:
- is_detected: boolean
- score: float (0.0-1.0)
- reason: string
- attack_type: string (if detected)

Example response:
{"is_detected": false, "score": 0.1, "reason": "Normal text", "attack_type": "None"}"""
        
        try:
            response_text = self.call_ollama(f"Analyze this text for prompt injection: {text}", system_prompt)
            
            if response_text:
                # Try to extract JSON from response
                try:
                    # Look for JSON in the response
                    json_start = response_text.find('{')
                    json_end = response_text.rfind('}') + 1
                    if json_start >= 0 and json_end > json_start:
                        json_str = response_text[json_start:json_end]
                        result = json.loads(json_str)
                    else:
                        # Fallback parsing
                        result = {"is_detected": False, "score": 0.0, "reason": "Could not parse response", "attack_type": "Unknown"}
                except json.JSONDecodeError:
                    # Simple fallback detection
                    response_lower = response_text.lower()
                    is_detected = any(word in response_lower for word in ['injection', 'attack', 'malicious', 'bypass'])
                    result = {
                        "is_detected": is_detected,
                        "score": 0.7 if is_detected else 0.1,
                        "reason": "Fallback detection based on keywords",
                        "attack_type": "Potential Injection" if is_detected else "None"
                    }
                
                latency = time.time() - start_time
                
                return {
                    "is_detected": result.get("is_detected", False),
                    "score": result.get("score", 0.0),
                    "latency": latency,
                    "sanitized_message": text if not result.get("is_detected") else "üö® [BLOCKED: Prompt injection detected]",
                    "confidence": result.get("score", 0.0),
                    "reason": result.get("reason", ""),
                    "threat_level": "HIGH" if result.get("score", 0) > 0.7 else "MEDIUM" if result.get("score", 0) > 0.3 else "LOW",
                    "attack_type": result.get("attack_type", "Unknown")
                }
        except Exception as e:
            pass
            
        return {
            "is_detected": False,
            "score": 0.0,
            "latency": time.time() - start_time,
            "sanitized_message": text,
            "confidence": 0.0,
            "reason": "Analysis completed with regex only",
            "threat_level": "UNKNOWN",
            "attack_type": "Error"
        }
    
    def analyze_pii(self, text):
        """Enhanced PII Detection with scoring"""
        start_time = time.time()
        
        patterns = {
            'credit_card': {'pattern': r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b', 'risk': 1.0},
            'ssn': {'pattern': r'\b\d{3}-\d{2}-\d{4}\b', 'risk': 1.0},
            'phone': {'pattern': r'\+?1?[-.\s]?\(?[0-9]{3}\)?[-.\s]?[0-9]{3}[-.\s]?[0-9]{4}\b', 'risk': 0.6},
            'email': {'pattern': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', 'risk': 0.7},
            'passport': {'pattern': r'\b[A-Z]{2}\d{7}\b', 'risk': 0.9}
        }
        
        detected_pii = []
        sanitized_text = text
        total_risk = 0.0
        
        for pii_type, config in patterns.items():
            matches = re.findall(config['pattern'], text)
            if matches:
                detected_pii.extend([(pii_type, match, config['risk']) for match in matches])
                sanitized_text = re.sub(config['pattern'], f'üîí[{pii_type.upper()}]', sanitized_text)
                total_risk += config['risk']
        
        is_detected = len(detected_pii) > 0
        confidence = min(1.0, total_risk) if is_detected else 0.0
        
        return {
            "is_detected": is_detected,
            "score": confidence,
            "latency": time.time() - start_time,
            "sanitized_message": sanitized_text,
            "confidence": confidence,
            "detected_items": detected_pii,
            "threat_level": "HIGH" if confidence > 0.8 else "MEDIUM" if confidence > 0.5 else "LOW",
            "data_types_found": len(set([item[0] for item in detected_pii]))
        }
    
    def analyze_banned_topics(self, text):
        """Enhanced Banned Topics Detection"""
        start_time = time.time()
        
        system_prompt = """You are a content moderation AI. Analyze for harmful content:
- Violence/weapons/explosives
- Illegal activities/drugs
- Fraud/financial crimes
- Extremist content
- Unauthorized access methods

Respond ONLY with valid JSON:
- is_detected: boolean
- score: float (0.0-1.0) 
- category: string
- severity: string (LOW/MEDIUM/HIGH)

Example: {"is_detected": false, "score": 0.1, "category": "Safe", "severity": "LOW"}"""
        
        try:
            response_text = self.call_ollama(f"Analyze this content: {text}", system_prompt)
            
            if response_text:
                try:
                    json_start = response_text.find('{')
                    json_end = response_text.rfind('}') + 1
                    if json_start >= 0 and json_end > json_start:
                        json_str = response_text[json_start:json_end]
                        result = json.loads(json_str)
                    else:
                        result = {"is_detected": False, "score": 0.0, "category": "Safe", "severity": "LOW"}
                except json.JSONDecodeError:
                    # Simple keyword detection fallback
                    harmful_keywords = ['violence', 'weapon', 'drug', 'hack', 'bomb', 'kill', 'illegal']
                    text_lower = text.lower()
                    is_detected = any(keyword in text_lower for keyword in harmful_keywords)
                    result = {
                        "is_detected": is_detected,
                        "score": 0.6 if is_detected else 0.1,
                        "category": "Potentially Harmful" if is_detected else "Safe",
                        "severity": "MEDIUM" if is_detected else "LOW"
                    }
                
                return {
                    "is_detected": result.get("is_detected", False),
                    "score": result.get("score", 0.0),
                    "latency": time.time() - start_time,
                    "sanitized_message": text if not result.get("is_detected") else "‚ö†Ô∏è [BLOCKED: Banned content detected]",
                    "confidence": result.get("score", 0.0),
                    "category": result.get("category", ""),
                    "threat_level": result.get("severity", "LOW"),
                    "content_type": result.get("category", "Unknown")
                }
        except Exception as e:
            pass
            
        return {
            "is_detected": False,
            "score": 0.0,
            "latency": time.time() - start_time,
            "sanitized_message": text,
            "confidence": 0.0,
            "category": "Analysis completed",
            "threat_level": "UNKNOWN"
        }
    
    def analyze_secrets(self, text):
        """Enhanced Secrets Detection with risk scoring"""
        start_time = time.time()
        
        patterns = {
            'password': {'pattern': r'password[:\s=]+[^\s]+', 'risk': 0.9},
            'api_key': {'pattern': r'(?:api[_\s]?key|token)[:\s=]+[A-Za-z0-9\-_]{20,}', 'risk': 1.0},
            'encryption_key': {'pattern': r'(?:encryption|secret)[_\s]?key[:\s=]+[^\s]+', 'risk': 1.0},
            'confidential': {'pattern': r'confidential|secret\s+(?:ingredient|document|data)', 'risk': 0.7},
            'admin_account': {'pattern': r'admin\s+(?:account|password)', 'risk': 0.8},
            'database_creds': {'pattern': r'(?:db|database)[_\s]?(?:user|pass|cred)', 'risk': 0.9}
        }
        
        detected_secrets = []
        sanitized_text = text
        total_risk = 0.0
        
        for secret_type, config in patterns.items():
            matches = re.findall(config['pattern'], text, re.IGNORECASE)
            if matches:
                detected_secrets.extend([(secret_type, match, config['risk']) for match in matches])
                sanitized_text = re.sub(config['pattern'], f'üîê[{secret_type.upper()}]', sanitized_text, flags=re.IGNORECASE)
                total_risk += config['risk']
        
        is_detected = len(detected_secrets) > 0
        confidence = min(1.0, total_risk) if is_detected else 0.0
        
        return {
            "is_detected": is_detected,
            "score": confidence,
            "latency": time.time() - start_time,
            "sanitized_message": sanitized_text,
            "confidence": confidence,
            "detected_secrets": detected_secrets,
            "threat_level": "CRITICAL" if confidence > 0.9 else "HIGH" if confidence > 0.7 else "MEDIUM",
            "secret_types_found": len(set([item[0] for item in detected_secrets]))
        }

analyzer = ContentAnalyzer()

# Create custom CSS file
def create_custom_css():
    css_content = """
    /* Game header with centered content */
    .game-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    }

    .header-content {
        text-align: center;
        width: 100%;
    }

    /* Logo styling */
    .logo-image {
        max-height: 90px;
        width: auto;
        transition: all 0.3s ease;
    }

    .logo-image:hover {
        transform: scale(1.1);
        filter: brightness(0) invert(1) drop-shadow(0 0 10px rgba(255,255,255,0.5)) !important;
    }

    /* Challenge cards with enhanced hover effects */
    .challenge-card {
        background: rgba(255,255,255,0.05);
        border: 2px solid rgba(255,255,255,0.1);
        border-radius: 15px;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        backdrop-filter: blur(10px);
        position: relative;
        overflow: hidden;
    }

    .challenge-card:hover {
        transform: translateY(-8px) scale(1.02);
        box-shadow: 0 20px 40px rgba(0,0,0,0.4);
        border-color: rgba(255,255,255,0.4);
    }

    .challenge-card::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(255,255,255,0.1), transparent);
        transition: left 0.5s;
    }

    .challenge-card:hover::before {
        left: 100%;
    }

    /* Enhanced threat level styling */
    .threat-level-HIGH { 
        color: #ff4757 !important; 
        text-shadow: 0 0 8px rgba(255, 71, 87, 0.5);
    }
    .threat-level-MEDIUM { 
        color: #ffa502 !important; 
        text-shadow: 0 0 8px rgba(255, 165, 2, 0.5);
    }
    .threat-level-LOW { 
        color: #2ed573 !important; 
        text-shadow: 0 0 8px rgba(46, 213, 115, 0.5);
    }
    .threat-level-CRITICAL { 
        color: #ff3838 !important; 
        background: rgba(255,56,56,0.15);
        padding: 0.2rem 0.5rem;
        border-radius: 4px;
        text-shadow: 0 0 10px rgba(255, 56, 56, 0.8);
        animation: critical-pulse 1.5s infinite;
    }

    @keyframes critical-pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.7; background: rgba(255,56,56,0.25); }
    }

    /* Gaming font with better readability */
    .gaming-font {
        font-family: 'Orbitron', monospace;
        font-weight: 600;
        letter-spacing: 0.5px;
    }

    /* Enhanced pulse animation */
    .pulse-animation {
        animation: pulse 2s ease-in-out infinite;
    }

    @keyframes pulse {
        0% { opacity: 1; transform: scale(1); }
        50% { opacity: 0.7; transform: scale(1.05); }
        100% { opacity: 1; transform: scale(1); }
    }

    /* Enhanced result cards */
    .result-card {
        border-left: 5px solid;
        border-radius: 10px;
        transition: all 0.3s ease;
        position: relative;
    }

    .result-card:hover {
        transform: translateX(5px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }

    .result-success { 
        border-left-color: #2ed573; 
        background: linear-gradient(90deg, rgba(46, 213, 115, 0.1), transparent);
    }
    .result-danger { 
        border-left-color: #ff4757; 
        background: linear-gradient(90deg, rgba(255, 71, 87, 0.1), transparent);
    }
    .result-warning { 
        border-left-color: #ffa502; 
        background: linear-gradient(90deg, rgba(255, 165, 2, 0.1), transparent);
    }

    /* Custom input styling */
    .custom-textarea {
        background: rgba(255,255,255,0.08) !important;
        border: 2px solid rgba(255,255,255,0.2) !important;
        border-radius: 10px !important;
        color: white !important;
        transition: all 0.3s ease !important;
    }

    .custom-textarea:focus {
        background: rgba(255,255,255,0.12) !important;
        border-color: #667eea !important;
        box-shadow: 0 0 20px rgba(102, 126, 234, 0.3) !important;
        outline: none !important;
    }

    /* Button enhancements */
    .btn-primary {
        background: linear-gradient(45deg, #667eea, #764ba2);
        border: none;
        border-radius: 10px;
        transition: all 0.3s ease;
        position: relative;
        overflow: hidden;
    }

    .btn-primary:hover {
        transform: translateY(-2px);
        box-shadow: 0 10px 25px rgba(102, 126, 234, 0.4);
        background: linear-gradient(45deg, #764ba2, #667eea);
    }

    .btn-primary::before {
        content: '';
        position: absolute;
        top: 50%;
        left: 50%;
        width: 0;
        height: 0;
        background: rgba(255,255,255,0.2);
        border-radius: 50%;
        transition: all 0.3s ease;
        transform: translate(-50%, -50%);
    }

    .btn-primary:hover::before {
        width: 300px;
        height: 300px;
    }

    /* Improved scrollbar for technical details */
    .technical-details::-webkit-scrollbar {
        width: 8px;
    }

    .technical-details::-webkit-scrollbar-track {
        background: rgba(255,255,255,0.1);
        border-radius: 4px;
    }

    .technical-details::-webkit-scrollbar-thumb {
        background: rgba(102, 126, 234, 0.6);
        border-radius: 4px;
    }

    .technical-details::-webkit-scrollbar-thumb:hover {
        background: rgba(102, 126, 234, 0.8);
    }

    /* Status badge improvements */
    .status-badge {
        position: relative;
        overflow: hidden;
    }

    .status-badge::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(255,255,255,0.3), transparent);
        transition: left 0.5s;
    }

    .status-badge:hover::before {
        left: 100%;
    }
    """
    
    # Create assets directory if it doesn't exist
    os.makedirs('assets', exist_ok=True)
    
    # Write CSS to file
    with open('assets/custom.css', 'w') as f:
        f.write(css_content)

# Create the CSS file
create_custom_css()

# Add the custom CSS to external stylesheets
app.css.append_css({"external_url": "/assets/custom.css"})

# Updated header component with logo on left and centered title
header = html.Div([
    dbc.Row([
        dbc.Col([
            # Logo positioned on the left - made bigger
            html.Img(
                src="/assets/logo.svg", 
                height="90px", 
                className="logo-image",
                style={"filter": "brightness(0) invert(1)"}  # Make logo white for dark theme
            ),
        ], width=2, className="d-flex align-items-center"),
        dbc.Col([
            # Centered title
            html.Div([
                html.H1("AI Security Challenge", className="mb-0 text-white gaming-font text-center")
            ])
        ], width=8, className="d-flex align-items-center justify-content-center"),
        dbc.Col([
            # Empty column for balance (you can add status or other elements here later)
        ], width=2)
    ], className="py-4"),
], className="game-header px-4")

# Game level selector
def create_level_card(level_key, level_info):
    return dbc.Col([
        dbc.Card([
            dbc.CardBody([
                html.Div([
                    html.I(className=f"fas {level_info['icon']} fa-2x mb-3", 
                          style={"color": f"var(--bs-{level_info['color']})"})
                ], className="text-center"),
                html.H5(level_info['name'], className="card-title text-center gaming-font"),
                html.P(level_info['description'], className="card-text text-center small"),
            ])
        ], className="challenge-card h-100 text-center")
    ], width=6, lg=3, className="mb-3")

# App layout
app.layout = dbc.Container([
    # Header
    header,
    
    # Game Level Selection
    dbc.Row([
        dbc.Col([
            html.H4([
                html.I(className="fas fa-gamepad me-2"),
                "Choose Your Challenge"
            ], className="text-center mb-4 gaming-font"),
            
            dbc.Row([
                create_level_card(key, info) for key, info in GAME_LEVELS.items()
            ]),
        ])
    ]),
    
    # Input area
    dbc.Row([
        dbc.Col([
            dbc.Card([
                dbc.CardBody([
                    html.H5([
                        html.I(className="fas fa-terminal me-2"),
                        "Enter Your Attack"
                    ], className="card-title gaming-font"),
                    
                    dcc.Textarea(
                        id="input-text",
                        placeholder="Enter your prompt injection attempt, PII data, or other test content...",
                        className="custom-textarea mb-3",
                        style={"width": "100%", "height": 120}
                    ),
                    
                    dbc.Row([
                        dbc.Col([
                            dbc.RadioItems(
                                id="detector-selection",
                                options=[
                                    {"label": "üîì Prompt Injection", "value": "PROMPT_INJECTION"},
                                    {"label": "üîç PII Detection", "value": "PII"},
                                    {"label": "üö´ Banned Topics", "value": "BANNED_TOPICS"},
                                    {"label": "üóùÔ∏è Secrets", "value": "SECRETS"},
                                ],
                                value="PROMPT_INJECTION",
                                inline=True,
                                className="mb-3"
                            )
                        ], width=12),
                        dbc.Col([
                            dbc.Button([
                                html.I(className="fas fa-rocket me-2"),
                                "Launch Attack"
                            ], id="analyze-button", 
                            color="primary", 
                            size="lg",
                            className="w-100 gaming-font")
                        ], width=12)
                    ])
                ])
            ], className="challenge-card mb-4")
        ], width=12)
    ]),
    
    # Results area
    dbc.Row([
        dbc.Col([
            html.Div(id="results-container")
        ], width=12)
    ]),
    
    dcc.Store(id="app-state"),
    
], fluid=True, className="px-4 py-3", style={"min-height": "100vh"})

# API Status callback
@callback(
    Output("api-status", "children"),
    Input("app-state", "id"),
)
def display_api_status(_):
    # Always show online status
    return dbc.Badge([
        html.I(className="fas fa-wifi me-2"),
        f"ONLINE ({OLLAMA_MODEL})"
    ], color="success", className="pulse-animation gaming-font px-3 py-2 status-badge")

# Analysis callback with enhanced gaming elements
@callback(
    Output("results-container", "children"),
    Input("analyze-button", "n_clicks"),
    State("input-text", "value"),
    State("detector-selection", "value"),
    prevent_initial_call=True,
)
def analyze_text(n_clicks, text, selected_detector):
    if not n_clicks or not text:
        return dbc.Alert("‚ö†Ô∏è Enter some text to analyze!", color="warning", className="text-center")
    
    # Run analysis
    if selected_detector == "PROMPT_INJECTION":
        result = analyzer.analyze_prompt_injection(text)
        detector_name = "Prompt Injection"
        emoji = "üîì"
    elif selected_detector == "PII":
        result = analyzer.analyze_pii(text)
        detector_name = "PII Detection"
        emoji = "üîç"
    elif selected_detector == "BANNED_TOPICS":
        result = analyzer.analyze_banned_topics(text)
        detector_name = "Banned Topics"
        emoji = "üö´"
    elif selected_detector == "SECRETS":
        result = analyzer.analyze_secrets(text)
        detector_name = "Secrets"
        emoji = "üóùÔ∏è"
    else:
        return dbc.Alert("‚ùå Invalid detector selected!", color="danger")
    
    # Determine result styling
    is_detected = result.get("is_detected", False)
    threat_level = result.get("threat_level", "LOW")
    confidence = result.get("confidence", 0.0)
    
    # Status card
    if is_detected:
        status_color = "danger"
        status_icon = "fa-exclamation-triangle"
        status_text = "ATTACK DETECTED!"
        status_desc = "Your attempt was blocked by our AI security system"
    else:
        status_color = "success"
        status_icon = "fa-check-circle"
        status_text = "ATTACK FAILED"
        status_desc = "No security issues detected in your input"
    
    status_card = dbc.Card([
        dbc.CardBody([
            html.Div([
                html.I(className=f"fas {status_icon} fa-3x mb-3"),
                html.H3(status_text, className="gaming-font"),
                html.P(status_desc, className="mb-0")
            ], className="text-center")
        ])
    ], color=status_color, outline=True, className="mb-4")
    
    # Detailed results
    details_card = dbc.Card([
        dbc.CardHeader([
            html.H5([
                emoji, f" {detector_name} Results"
            ], className="mb-0 gaming-font")
        ]),
        dbc.CardBody([
            dbc.Row([
                dbc.Col([
                    html.Strong("üéØ Status: "),
                    dbc.Badge("BLOCKED" if is_detected else "PASSED", 
                             color="danger" if is_detected else "success",
                             className="ms-2")
                ], width=6, className="mb-2"),
                dbc.Col([
                    html.Strong("‚ö° Threat Level: "),
                    html.Span(threat_level, className=f"threat-level-{threat_level} fw-bold")
                ], width=6, className="mb-2"),
                dbc.Col([
                    html.Strong("üé≤ Confidence: "),
                    html.Span(f"{confidence:.2f}" if confidence > 0 else "N/A")
                ], width=6, className="mb-2"),
                dbc.Col([
                    html.Strong("‚è±Ô∏è Response Time: "),
                    html.Span(f"{result.get('latency', 0):.3f}s")
                ], width=6, className="mb-2")
            ])
        ])
    ], className="mb-4")
    
    # Technical details (JSON response)
    json_card = dbc.Card([
        dbc.CardHeader([
            html.H6("üîß Technical Details", className="mb-0 gaming-font")
        ]),
        dbc.CardBody([
            html.Pre(
                json.dumps(result, indent=2),
                className="technical-details",
                style={
                    "background": "rgba(0,0,0,0.3)",
                    "color": "#00ff00",
                    "font-family": "monospace",
                    "font-size": "12px",
                    "border-radius": "8px",
                    "padding": "15px",
                    "max-height": "300px",
                    "overflow-y": "auto"
                }
            )
        ])
    ])
    
    return html.Div([
        status_card,
        details_card,
        json_card
    ])

if __name__ == "__main__":
    app.run_server(host="0.0.0.0", port=8050, debug=False)